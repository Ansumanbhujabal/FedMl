{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMgNvaDtg9fBazJ/OdN3K7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db5IpdLOF8ry"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import flwr as fl\n",
        "from flwr.common import Context\n",
        "from collections import OrderedDict\n",
        "\n",
        "# List of class names\n",
        "classes = ['glioma', 'meningioma', 'pituitary', 'notumor']\n",
        "\n",
        "# Training and testing directories\n",
        "base_train_dir = \"/content/Training\"\n",
        "base_test_dir = \"/content/Testing\"\n",
        "\n",
        "# Organize the directory structure for training and testing data\n",
        "def correct_directory_structure(base_dir):\n",
        "    for class_name in classes:\n",
        "        class_dir = os.path.join(base_dir, class_name)\n",
        "        subfolder_dir = os.path.join(class_dir, class_name)\n",
        "        if os.path.exists(subfolder_dir):\n",
        "            for img in os.listdir(subfolder_dir):\n",
        "                shutil.move(os.path.join(subfolder_dir, img), class_dir)\n",
        "            shutil.rmtree(subfolder_dir)\n",
        "\n",
        "# Fix the training and testing directories\n",
        "correct_directory_structure(base_train_dir)\n",
        "correct_directory_structure(base_test_dir)\n",
        "\n",
        "# Data paths for the organized directories\n",
        "train_dirs = [\n",
        "    # '/content/Training/glioma',\n",
        "    # '/content/Training/meningioma',\n",
        "    # '/content/Training/pituitary',\n",
        "    # '/content/Training/notumor'\n",
        "    \"/content/Training\"\n",
        "]\n",
        "\n",
        "test_dirs = [\n",
        "    # '/content/Testing/glioma',\n",
        "    # '/content/Testing/meningioma',\n",
        "    # '/content/Testing/pituitary',\n",
        "    # '/content/Testing/notumor'\n",
        "    \"/content/Testing\"\n",
        "]\n",
        "\n",
        "# Data generators for training and testing\n",
        "def get_data_generators(train_dirs, test_dirs, target_size=(224, 224), batch_size=32):\n",
        "    # ImageDataGenerator with rescaling\n",
        "    train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "    # Load the training data from multiple directories\n",
        "    train_generators = []\n",
        "    for train_dir in train_dirs:\n",
        "        print(f\"Loading training data from: {train_dir}\")\n",
        "        train_gen = train_datagen.flow_from_directory(\n",
        "            train_dir,\n",
        "            target_size=target_size,\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical',\n",
        "            shuffle=True\n",
        "        )\n",
        "        train_generators.append(train_gen)\n",
        "\n",
        "    # Load the test data from multiple directories\n",
        "    test_generators = []\n",
        "    for test_dir in test_dirs:\n",
        "        print(f\"Loading testing data from: {test_dir}\")\n",
        "        test_gen = test_datagen.flow_from_directory(\n",
        "            test_dir,\n",
        "            target_size=target_size,\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical',\n",
        "            shuffle=False\n",
        "        )\n",
        "        test_generators.append(test_gen)\n",
        "\n",
        "    return train_generators, test_generators\n",
        "\n",
        "# Example usage: Get data generators\n",
        "train_generators, test_generators = get_data_generators(train_dirs, test_dirs)"
      ],
      "metadata": {
        "id": "xf8jBEimF9S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_dir in train_dirs:\n",
        "    print(f\"Checking contents of {train_dir}:\")\n",
        "    print(os.listdir(train_dir))\n",
        "\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    '/content/Training',  # Parent directory containing the class folders\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "for train_dir in train_dirs:\n",
        "    print(os.listdir(train_dir))"
      ],
      "metadata": {
        "id": "D1j3iceSGFvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# VGG16 model setup\n",
        "def build_model():\n",
        "    vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    vgg_base.trainable = False\n",
        "\n",
        "    x = Flatten()(vgg_base.output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=vgg_base.input, outputs=x)\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Flower Client for federated learning\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, train_generator, test_generator):\n",
        "        self.model = model\n",
        "        self.train_generator = train_generator\n",
        "        self.test_generator = test_generator\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        if weights is not None and len(weights) == len(self.model.get_weights()):\n",
        "            self.model.set_weights(weights)\n",
        "        else:\n",
        "            print(\"Warning: Mismatch in the number of model weights.\")\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_weights(parameters)\n",
        "        self.model.fit(self.train_generator, epochs=1, verbose=2)\n",
        "        return self.get_weights(), len(self.train_generator), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_weights(parameters)\n",
        "        loss, accuracy = self.model.evaluate(self.test_generator, verbose=2)\n",
        "        return loss, len(self.test_generator), {\"accuracy\": accuracy}\n",
        "\n",
        "# Client function for Flower simulation\n",
        "def client_fn(context: Context):\n",
        "    partition_id = int(context.node_config.get(\"partition_id\", 0))\n",
        "    model = build_model()\n",
        "\n",
        "    # Assign directories based on the partition ID\n",
        "    train_generators, test_generators = get_data_generators([train_dirs[partition_id]], [test_dirs[partition_id]])\n",
        "    return FlowerClient(model, train_generators[0], test_generators[0])\n",
        "\n",
        "# Global evaluation function for federated learning\n",
        "def evaluate(server_round, parameters, config):\n",
        "    model = build_model()\n",
        "    if parameters:\n",
        "        model.set_weights(parameters)\n",
        "\n",
        "    _, test_generators = get_data_generators(train_dirs, test_dirs)\n",
        "    loss, accuracy = 0, 0\n",
        "\n",
        "    for test_generator in test_generators:\n",
        "        current_loss, current_accuracy = model.evaluate(test_generator, verbose=2)\n",
        "        loss += current_loss\n",
        "        accuracy += current_accuracy\n",
        "\n",
        "    loss /= len(test_generators)\n",
        "    accuracy /= len(test_generators)\n",
        "\n",
        "    print(f\"Round {server_round} accuracy: {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "# Federated Learning Strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    initial_parameters=None,\n",
        "    evaluate_fn=evaluate,\n",
        "    on_fit_config_fn=lambda rnd: {\"epoch_global\": rnd},\n",
        ")\n",
        "\n",
        "# Start the federated learning simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=4,\n",
        "    config=fl.server.ServerConfig(num_rounds=3),\n",
        "    strategy=strategy,\n",
        "    client_resources={\"num_cpus\": 2},\n",
        ")\n"
      ],
      "metadata": {
        "id": "C5I_ooXIGGMj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}